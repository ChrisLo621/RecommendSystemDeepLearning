{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, json, time\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, itertools, shutil,pymysql\n",
    "import datetime\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "# 多核\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "#\n",
    "import tensorflow as tf\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict, Counter\n",
    "utils = reload('utils.utils')\n",
    "from LotteryMFDNN import ModelMfDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(start, end, intv):\n",
    "    \n",
    "    start = datetime.datetime.strptime(start,\"%Y%m%d\")\n",
    "    end = datetime.datetime.strptime(end,\"%Y%m%d\")\n",
    "    diff = (end  - start ) / intv\n",
    "    for i in range(intv):\n",
    "        yield (start + diff * i).strftime(\"%Y%m%d\")\n",
    "    yield end.strftime(\"%Y%m%d\")\n",
    "\n",
    "def quantile(array,bottom,top):\n",
    "    return np.percentile(array,bottom),np.percentile(array,top)\n",
    "\n",
    "def ConnectMemSQL(query,columns):\n",
    "    conn=pymysql.connect(host='10.28.1.12',port=3306,user='BI_hp',password='djo62u4fu6BI',db='OLAP',charset='utf8')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    conn.close()\n",
    "    rows=cursor.fetchall()\n",
    "    #data=pd.DataFrame([[ij for ij in i] for i in rows],columns=columns)\n",
    "    data=pd.DataFrame.from_records(list(rows),columns=columns)\n",
    "    return data\n",
    "\n",
    "def wagers_df(i):\n",
    "    global start_list\n",
    "    global end_list\n",
    "   # query='select User_Key,GameType_Key,WagersTotal from Fact_Aggr_Wagers_User \\\n",
    "   # where GameKind_Key in (121,122)  and RoundDate_Key between '+start_list[i]+' and '+end_list[i]\n",
    "    query='select a.RoundDate_Key,a.Hall_Key,a.AG_Key,b.Payway_Key,a.User_Key,a.GameType_Key,a.WagersTotal \\\n",
    "           from Fact_Aggr_Wagers_User as a,Dim_Hall as b \\\n",
    "           where a.GameKind_Key  in (121,122) and a.Hall_Key=b.Hall_Key and  a.RoundDate_Key between '+start_list[i]+' and '+end_list[i] +' and b.API=0 and a.Test=0 and a.Hall_Test=0'\n",
    "   # print(query)\n",
    "    #print('==============================================================================================================')\n",
    "    colsname=['RoundDate_Key','Hall_Key','AG_Key','Payway_Key','User_Key','GameType_Key','WagersTotal']\n",
    "    df=ConnectMemSQL(query,colsname)\n",
    "    return df\n",
    "    #print(query)\n",
    "\n",
    "def web_type_df(i):\n",
    "    global start_list\n",
    "    global end_list\n",
    "    \n",
    "    query='select RoundDate_Key,User_Key,GameType_Key,count(if(WebVersion=7,WagersID,NULL)) as wag_7 , count(if(WebVersion!=7,WagersID,NULL)) as wag_0 \\\n",
    "           from Fact_Wagers_2_FastReport \\\n",
    "           where RoundDate_Key between '+start_list[i]+' and '+end_list[i]+' group by 1,2,3'\n",
    "    \n",
    "   # print(query)\n",
    "    #print('==============================================================================================================')\n",
    "    colsname=['RoundDate_Key','User_Key','GameType_Key','Wag_7','Wag_0']\n",
    "    df=ConnectMemSQL(query,colsname)\n",
    "    return df \n",
    "    \n",
    "    \n",
    "    \n",
    "def rank_function(df):\n",
    "    df['rating']=df.WagersTotal.rank(ascending=True).head(20)\n",
    "    return df\n",
    "\n",
    "\n",
    "def rating_function(df):\n",
    "    \n",
    "   # total_wagers = sum(np.log(df.WagersTotal))\n",
    "    \n",
    "   # df['rating']= df['WagersTotal'].apply(lambda x : np.log(x)/total_wagers if np.log(x)>=0 and total_wagers>0  else 0.0) #(np.log(df.WagersTotal)/)\n",
    "    #df['data'].apply(lambda x: 'true' if x <= 2.5 else 'false')\n",
    "    df['rating']=(df.WagersTotal/sum(df.WagersTotal))\n",
    "    return df\n",
    "\n",
    "\n",
    "def smaple_func(df):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df.groupby(['User_Key','GameType_Key','Hall_Key','AG_Key','Payway_Key'])['RoundDate_Key','WagersTotal'].max().reset_index().tail(10)\n",
    "    \n",
    "\n",
    "def avg_function(df):\n",
    "    return np.mean(df.Rating.values)\n",
    "\n",
    "def apply_parallel(df,func):\n",
    "    ret=Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in df.groupby(['User_Key']))\n",
    "    return pd.concat(ret)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(u,df):  \n",
    "    queue=[]\n",
    "    columns=[\"hall_id_trans\",\"ag_id_trans\",\"payway\",\"user_id\",\"query_game_ids\",\"game_id_trans\"\n",
    "             ,\"web_like_type\",\"genres\",\"web_type_0\",\"web_type_7\"\n",
    "             ,\"rating\",\"avg_rating\",\"month\",\"day\",\"week_day\"\n",
    "             ,\"round_time\"\n",
    "            ]\n",
    "\n",
    "    df=df.sort_values(\"rating\",ascending=True)\n",
    "    for i,(_,r) in enumerate(df.iterrows()):\n",
    "        \n",
    "        queue.append([int(r.hall_id_trans),int(r.ag_id_trans),int(r.Payway_Key),int(r.User_Key),df.game_id_trans[:i].tolist()+df.game_id_trans[i+1:].tolist()\n",
    "                      ,int(r.game_id_trans),int(r.web_like_type),r.genres,r.web_type_0\n",
    "                      ,r.web_type_7,r.rating,r.avg_rating,int(r.month),int(r.day),int(r.week_day)\n",
    "                      ,r.round_time\n",
    "                     ])\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(queue,columns=columns) \n",
    "\n",
    "\n",
    "def preprocess(u,df):  \n",
    "    queue=[]\n",
    "    columns=[\"hall_id_trans\",\"ag_id_trans\",\"payway\",\"user_id\"\n",
    "             ,\"query_game_ids\",\"game_id_trans\"\n",
    "             ,\"web_like_type\",\"genres\",\"web_type_0\",\"web_type_7\"\n",
    "             ,\"rating\",\"avg_rating\"\n",
    "             ,\"daily_count\"\n",
    "            ]\n",
    "\n",
    "    df=df.sort_values(\"rating\",ascending=True)\n",
    "    for i,(_,r) in enumerate(df.iterrows()):\n",
    "        \n",
    "        queue.append([int(r.hall_id_trans),int(r.ag_id_trans),int(r.Payway_Key),int(r.User_Key)\n",
    "                      ,df.game_id_trans[:i].tolist()+df.game_id_trans[i+1:].tolist()\n",
    "                      ,int(r.game_id_trans),int(r.web_like_type),r.genres,r.web_type_0\n",
    "                      ,r.web_type_7,r.rating,r.avg_rating\n",
    "                      ,r.daily_count\n",
    "                     ])\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(queue,columns=columns) \n",
    "\n",
    "\n",
    "\n",
    "def preprocessTrain(u,df):  \n",
    "    queue=[]\n",
    "    columns=[\"hall_id_trans\",\"ag_id_trans\",\"user_id_trans\"\n",
    "             ,\"query_game_ids\",\"game_id_trans\"\n",
    "             ,\"genres\",\"web_type_0\",\"web_type_7\"\n",
    "             ,\"rating\",\"avg_rating\"\n",
    "             ,\"daily_count\"\n",
    "            \n",
    "            ]\n",
    "    \n",
    "    df=df.sort_values(\"rating\",ascending=True)  \n",
    "\n",
    "    for i,(_,r) in enumerate(df.iterrows()):\n",
    "\n",
    "        queue.append([int(r.hall_id_trans),int(r.ag_id_trans),int(r.user_id_trans)\n",
    "                      ,df.game_id_trans[:i].tolist()+df.game_id_trans[i+1:].tolist()\n",
    "                      ,int(r.game_id_trans),r.genres,r.web_type_0\n",
    "                      ,r.web_type_7,r.rating,r.avg_rating\n",
    "                      ,r.daily_count\n",
    "                     \n",
    "                     ])\n",
    "\n",
    "        \n",
    "    return pd.DataFrame(queue,columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessTest(u,df,train_hist):  \n",
    "    queue=[]\n",
    "    columns=[\"hall_id_trans\",\"ag_id_trans\",\"user_id_trans\"\n",
    "             ,\"query_game_ids\",\"game_id_trans\"\n",
    "             ,\"genres\",\"web_type_0\",\"web_type_7\"\n",
    "             ,\"rating\",\"avg_rating\"\n",
    "             ,\"daily_count\"\n",
    "            \n",
    "            ]\n",
    "    \n",
    "    df=df.sort_values(\"rating\",ascending=True)\n",
    "    \n",
    "        #user_game_hist = train_hist.query(\"User_Key=={}\".format(u)).game_id_trans\n",
    "    user_game_hist = train_hist[train_hist.user_id_trans==u].game_id_trans\n",
    "    #user_web_like_type = train_hist[train_hist.user_id_trans==u].web_like_type\n",
    "    \n",
    "    for i,(_,r) in enumerate(df.iterrows()):\n",
    "\n",
    "            all_hist = set(user_game_hist.tolist())\n",
    "                  \n",
    "            queue.append([int(r.hall_id_trans),int(r.ag_id_trans),int(r.user_id_trans)\n",
    "                      ,df.game_id_trans[:i].tolist()+df.game_id_trans[i+1:].tolist()\n",
    "                      ,int(r.game_id_trans),r.genres,r.web_type_0\n",
    "                      ,r.web_type_7,r.rating,r.avg_rating\n",
    "                      ,r.daily_count\n",
    "                     \n",
    "                     ])\n",
    "        \n",
    "    return pd.DataFrame(queue,columns=columns)\n",
    "\n",
    "\n",
    "def Date_To_Numeric(date):\n",
    "    return date.year*10000+date.month*100+date.day\n",
    "\n",
    "class recordDate:\n",
    "    def __init__(self):\n",
    "        self.run_date = datetime.datetime.now()        \n",
    "        self.end_date = self.run_date - datetime.timedelta(days=2)\n",
    "        self.start_date = self.end_date - datetime.timedelta(days=120)\n",
    "        self.test_date = self.end_date - datetime.timedelta(days=30)\n",
    "        self.date_num_dict = {}\n",
    "        \n",
    "        self.date_num_dict['run_date'] = self.dateToNumeric(self.run_date)\n",
    "        self.date_num_dict['start_date'] = self.dateToNumeric(self.start_date)\n",
    "        self.date_num_dict['end_date'] = self.dateToNumeric(self.end_date)\n",
    "        self.date_num_dict['test_date'] = self.dateToNumeric(self.test_date)\n",
    "        self.n_split_date = 60\n",
    "    def dateToNumeric(self,date):\n",
    "        \n",
    "        return date.year*10000+date.month*100+date.day\n",
    "    \n",
    "    def splitDate(self):\n",
    "        time_split=list(date_range(str(self.date_num_dict['start_date']),str(self.date_num_dict['end_date']),self.n_split_date))\n",
    "        start=0\n",
    "        start_list=[]\n",
    "        end_list=[]\n",
    "        for t in range(len(time_split)-1):\n",
    "            if start ==0:\n",
    "                start=time_split[t]\n",
    "                end=time_split[t+1]\n",
    "            else:\n",
    "                start=datetime.datetime.strptime(end,\"%Y%m%d\")+datetime.timedelta(days=1)\n",
    "                start=start.strftime(\"%Y%m%d\")\n",
    "                end=time_split[t+1]\n",
    "        \n",
    "            start_list.append(start)\n",
    "            end_list.append(end)\n",
    "        return start_list,end_list\n",
    "\n",
    "class timetick:\n",
    "    def __init__(self,start):\n",
    "        self.start=start\n",
    "    def tick(self,time):\n",
    "        sec=time-self.start\n",
    "        self.start=time\n",
    "        return str(sec) + \" sec\"\n",
    "\n",
    "def dateToNumeric(date):\n",
    "    return date.year*10000+date.month*100+date.day\n",
    "time_delta=timetick(timeit.default_timer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date information => {'run_date': 20190312, 'start_date': 20181110, 'end_date': 20190310, 'test_date': 20190208}\n"
     ]
    }
   ],
   "source": [
    "date = recordDate()\n",
    "print('date information =>',date.date_num_dict)\n",
    "start_list,end_list = date.splitDate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 3, 12, 11, 13, 3, 285583)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.run_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get web data used time :  280.13700297661126 sec\n"
     ]
    }
   ],
   "source": [
    "web_df=web_type_df(0)\n",
    "for d in range(len(start_list)-1):\n",
    "    web_df=web_df.append(web_type_df(d+1), ignore_index=True)\n",
    "    time.sleep(0.5)\n",
    "print(\"get web data used time : \",time_delta.tick(timeit.default_timer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='select GameType_Key,GameType_Name from Dim_GameType where GameKind_Key in (122,121)'\n",
    "colsname=['GameType_Key','GameType_Name']\n",
    "Dim_GameType=ConnectMemSQL(query,colsname)\n",
    "\n",
    "\n",
    "item=pd.read_csv(\"./ItemData/item_category.csv\")\n",
    "item=item.fillna(0)\n",
    "item_dict={}\n",
    "label_dict={}\n",
    "key_dict={}\n",
    "\n",
    "for _,row in Dim_GameType.iterrows():\n",
    "    key_dict[row['GameType_Name']]=row['GameType_Key']\n",
    "\n",
    "for index ,row in item.iteritems():\n",
    "    label_dict[index]=[]\n",
    "\n",
    "count=0\n",
    "for k,v in label_dict.items():\n",
    "    label_dict[k]=count\n",
    "    count+=1\n",
    "\n",
    "for index, row in item.iteritems():\n",
    "   # print(index)\n",
    "    #print(row.values)\n",
    "    items_name=list(filter((0).__ne__, row.values.tolist()))\n",
    "    for i in items_name:\n",
    "        item_dict[key_dict[i.replace(\" \",\"\")]]=[]\n",
    "\n",
    "for index,row in item.iteritems():\n",
    "    items_name=list(filter((0).__ne__, row.values.tolist()))\n",
    "    for i in items_name:\n",
    "        item_dict[key_dict[i.replace(\" \",\"\")]]+=[label_dict[index]]\n",
    "    #item_dict[]=list(filter((0).__ne__, index))\n",
    "    \n",
    "n_game=len(item_dict)\n",
    "n_genres=len(label_dict)\n",
    "\n",
    "item_data=pd.DataFrame(pd.Series(item_dict)).reset_index()\n",
    "item_data.columns=[\"GameType_Key\",\"genres\"]\n",
    "\n",
    "item_le=LabelEncoder()\n",
    "item_le.fit(item_data.GameType_Key)\n",
    "item_data['game_id_trans']=item_le.transform(item_data.GameType_Key)\n",
    "\n",
    "max_n_genres=item_data.genres.map(len).max()\n",
    "n_game = item_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_detail=pd.read_csv(\"./ItemData/item_detail.csv\")\n",
    "\n",
    "queue=[]\n",
    "cols_name=[\"GameType_Key\",\"round_time\",\"daily_count\",\"game_result\"]\n",
    "for i,r in item_detail.iterrows():\n",
    "    queue.append([int(key_dict[r.GameType_Name]),r.time,r.counts,r.result])\n",
    "item_detail=pd.DataFrame(queue,columns=cols_name)\n",
    "item_data=pd.merge(item_data,item_detail,on=[\"GameType_Key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get wagers data used time :  285.7609623633325 sec\n"
     ]
    }
   ],
   "source": [
    "df=wagers_df(0)\n",
    "for d in range(len(start_list)-1):\n",
    "    df=df.append(wagers_df(d+1), ignore_index=True)\n",
    "    time.sleep(0.5)\n",
    " #  plit_df(d+1) \n",
    "#print(df.head())\n",
    "print(\"get wagers data used time : \",time_delta.tick(timeit.default_timer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    #df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    df_out = df_in.loc[df_in[col_name] > fence_low]\n",
    "    return df_out\n",
    "def web_preprocess(df):\n",
    "    queue=[]\n",
    "    columns=[\"game_id_trans\",\"web_type_0\",\"web_type_7\"]\n",
    "    for i in np.unique(df.game_id_trans.values):\n",
    "        \n",
    "        type0_percentage=df[(df.game_id_trans==i) & (df.web_like_type==0)]['count_percentage'].values.tolist()[0]\n",
    "        type7_percentage=df[(df.game_id_trans==i) & (df.web_like_type==1)]['count_percentage'].values.tolist()[0]\n",
    "        queue.append([int(i),type0_percentage,type7_percentage])\n",
    "    return pd.DataFrame(queue,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.RoundDate_Key<date.date_num_dict['test_date']].reset_index()\n",
    "test_df = df[df.RoundDate_Key>=date.date_num_dict['test_date']].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generateData:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.web_le = None\n",
    "        self.hall_le = None\n",
    "        self.ag_le = None\n",
    "        self.payway_le = None\n",
    "\n",
    "\n",
    "    def preprocData(self,df,web_df,item_data,train = True,avg_r = None):\n",
    "          if train :\n",
    "            self.web_le = LabelEncoder()\n",
    "            self.hall_le = LabelEncoder()\n",
    "            self.ag_le = LabelEncoder()\n",
    "            self.payway_le = LabelEncoder()\n",
    "            \n",
    "          #filter days = 1\n",
    "          user_days_count=pd.DataFrame(df.groupby(['User_Key'])['RoundDate_Key'].agg('count')).reset_index()\n",
    "          user_days_count=user_days_count.rename(index=str,columns={\"RoundDate_Key\":\"days\"})\n",
    "          #filter games = 1\n",
    "          user_games_count=pd.DataFrame(df.groupby(['User_Key'])['GameType_Key'].nunique()).reset_index()\n",
    "          user_games_count=user_games_count.rename(index=str,columns={\"GameType_Key\":\"games\"})\n",
    "          user_days_count,user_games_count=user_days_count[user_days_count.days>1],user_games_count[user_games_count.games>1]\n",
    "          # remove outlier days,games\n",
    "          user_days_in_value = remove_outlier(user_days_count,'days')\n",
    "          user_games_in_value = remove_outlier(user_games_count,'games')\n",
    "          user_in_value = pd.merge(user_days_in_value,user_games_in_value,on = 'User_Key',how='inner')\n",
    "          df_in_value = pd.merge(df,user_games_in_value,on='User_Key',how='inner')\n",
    "          # group by users , items and sum of wagers\n",
    "          df_in_value = df_in_value.groupby(['Hall_Key','AG_Key','User_Key','GameType_Key'])['WagersTotal'].sum().reset_index()\n",
    "          # remove wagers outlier\n",
    "          df_in_value = remove_outlier(df_in_value,'WagersTotal')\n",
    "          # balance daily round and WagersTotal\n",
    "        \n",
    "        #  for i,j in df_in_value.iterrows():\n",
    "         #       daily_round = item_data[item_data['GameType_Key']==j['GameType_Key']]['daily_count'].values[0]\n",
    "          #      j['WagersTotal'] = j['WagersTotal'] / daily_round\n",
    "          c = df_in_value.columns\n",
    "          df_in_value = pd.merge(item_data,df_in_value,on=\"GameType_Key\",how=\"left\")\n",
    "          df_in_value['WagersTotal'] = df_in_value['WagersTotal'] / df_in_value['daily_count']\n",
    "          df_in_value = df_in_value[c]\n",
    "          \n",
    "          # rating \n",
    "          df_in_value = apply_parallel(df_in_value,rating_function)\n",
    "    \n",
    "          # Web\n",
    "          web_df_ = pd.merge(web_df,user_in_value,on=\"User_Key\",how=\"inner\")\n",
    "          web_df_ = web_df_.groupby(['User_Key','GameType_Key'])[['Wag_7','Wag_0']].sum().reset_index()\n",
    "          web_df_['web_max']=web_df_[['Wag_7','Wag_0']].idxmax(axis=1)\n",
    "          # merge web_df_ and rating df\n",
    "          df_in_value = pd.merge(web_df_,df_in_value,on=['User_Key','GameType_Key'],how='left')\n",
    "          df_in_value = df_in_value.dropna()\n",
    "          # merge item_data and web + rating df \n",
    "          df_in_value=pd.merge(item_data,df_in_value,on=\"GameType_Key\",how=\"left\")\n",
    "          df_in_value=df_in_value.dropna()\n",
    "    \n",
    "          if train :\n",
    "            self.web_le.fit(df_in_value.web_max)\n",
    "            \n",
    "          df_in_value['web_like_type'] = self.web_le.transform(df_in_value.web_max)\n",
    "          if train :\n",
    "                \n",
    "              # compute avg rating by items\n",
    "              avg_rating=pd.DataFrame(df_in_value.groupby('game_id_trans').rating.mean() \\\n",
    "                               .fillna(df_in_value.rating.mean()))\n",
    "    \n",
    "              avg_rating=avg_rating.reset_index()\n",
    "              avg_rating=avg_rating.rename(index=str,columns={'rating':'avg_rating'})\n",
    "          else:\n",
    "              avg_rating = avg_r\n",
    "          # add avg rating on item + web + rating df \n",
    "          df_in_value=pd.merge(avg_rating,df_in_value,on=['game_id_trans'],how='left')\n",
    "          # add avg rating on item data\n",
    "          item_data=pd.merge(item_data,avg_rating,on=['game_id_trans'],how='outer')\n",
    "          # = = = = = = = = = = = = = = = = == = = = = = = = = = = =\n",
    "          # compute web like percentage\n",
    "          game_web_count=pd.DataFrame(df_in_value.groupby(['game_id_trans','web_like_type'])\n",
    "                 .web_like_type.count().reset_index(name='count'))\n",
    "    \n",
    "          for i in np.unique(game_web_count.game_id_trans.values):\n",
    "              for j in [0,1]:\n",
    "                  if game_web_count[(game_web_count.game_id_trans==i) & (game_web_count.web_like_type==j)].empty == True:\n",
    "                      insert_row=pd.DataFrame([[i,j,0]],columns=['game_id_trans', 'web_like_type', 'count'])\n",
    "                      game_web_count=game_web_count.append(insert_row)\n",
    "          game_web_max_count=pd.DataFrame(game_web_count.groupby(['game_id_trans'])['count'].sum().reset_index(name='sum_count'))\n",
    "    \n",
    "    \n",
    "          game_web_count=pd.merge(game_web_count,game_web_max_count,on=['game_id_trans'],how='outer')\n",
    "          game_web_count['count_percentage']=game_web_count['count']/game_web_count['sum_count']\n",
    "    \n",
    "          game_web_percent=web_preprocess(game_web_count)\n",
    "          df_in_value=pd.merge(df_in_value,game_web_percent,on=\"game_id_trans\",how=\"outer\")\n",
    "    \n",
    "          item_data=pd.merge(item_data,game_web_percent,on='game_id_trans',how='inner')\n",
    "    \n",
    "          return df_in_value,item_data,avg_rating,self.web_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc training data used time :  196.77248066104949 sec\n",
      "preproc testing data used time :  121.1968891415745 sec\n"
     ]
    }
   ],
   "source": [
    "gendata = generateData()\n",
    "train_preproc,tr_item_data,avg_rating,web_le = gendata.preprocData(train_df,web_df,item_data)\n",
    "print(\"preproc training data used time : \",time_delta.tick(timeit.default_timer()))\n",
    "test_preproc,test_item_data, _,_ = gendata.preprocData(df = test_df,web_df=web_df,item_data=item_data,train = False,avg_r = avg_rating)\n",
    "print(\"preproc testing data used time : \",time_delta.tick(timeit.default_timer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preproc_ = train_preproc.copy()\n",
    "test_preproc_ = test_preproc.copy()\n",
    "\n",
    "train_users = train_preproc_.User_Key.unique()\n",
    "test_users = test_preproc_.User_Key.unique()\n",
    "\n",
    "train_test_users = np.intersect1d(train_users,test_users)\n",
    "\n",
    "train_preproc_ = train_preproc_[train_preproc_.User_Key.isin(train_test_users)]\n",
    "test_preproc_ = test_preproc_[test_preproc_.User_Key.isin(train_test_users)]\n",
    "\n",
    "all_preproc = train_preproc_.append(test_preproc_)\n",
    "\n",
    "hall_le = LabelEncoder()\n",
    "ag_le = LabelEncoder()\n",
    "payway_le = LabelEncoder()\n",
    "user_le = LabelEncoder()\n",
    "\n",
    "hall_le.fit(all_preproc['Hall_Key'])\n",
    "ag_le.fit(all_preproc['AG_Key'])\n",
    "#payway_le.fit(all_preproc['Payway_Key'])\n",
    "user_le.fit(all_preproc['User_Key'])\n",
    "\n",
    "train_preproc_['hall_id_trans'] = hall_le.transform(train_preproc_['Hall_Key'])\n",
    "test_preproc_['hall_id_trans'] = hall_le.transform(test_preproc_['Hall_Key'])\n",
    "\n",
    "train_preproc_['ag_id_trans'] = ag_le.transform(train_preproc_['AG_Key'])\n",
    "test_preproc_['ag_id_trans'] = ag_le.transform(test_preproc_['AG_Key'])\n",
    "\n",
    "#train_preproc_['payway_id_trans'] = payway_le.transform(train_preproc_['Payway_Key'])\n",
    "#test_preproc_['payway_id_trans'] = payway_le.transform(test_preproc_['Payway_Key'])\n",
    "\n",
    "train_preproc_['user_id_trans'] = user_le.transform(train_preproc_['User_Key'])\n",
    "test_preproc_['user_id_trans'] = user_le.transform(test_preproc_['User_Key'])\n",
    "\n",
    "all_preproc = train_preproc_.append(test_preproc_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave one out  training and testing data used time :  1519.263577081263 sec\n"
     ]
    }
   ],
   "source": [
    "trProcessed=Parallel(n_jobs=multiprocessing.cpu_count())(delayed(preprocessTrain)(u,d) for u,d in train_preproc_.groupby(\"user_id_trans\"))\n",
    "teProcessed=Parallel(n_jobs=multiprocessing.cpu_count())(delayed(preprocessTest)(u,d,train_preproc_) for u,d in test_preproc_.groupby(\"user_id_trans\"))\n",
    "\n",
    "trProcessed=pd.concat(trProcessed)\n",
    "teProcessed=pd.concat(teProcessed)\n",
    "\n",
    "print(\"leave one out  training and testing data used time : \",time_delta.tick(timeit.default_timer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hall_id_trans</th>\n",
       "      <th>ag_id_trans</th>\n",
       "      <th>user_id_trans</th>\n",
       "      <th>query_game_ids</th>\n",
       "      <th>query_game_ids_len</th>\n",
       "      <th>game_id_trans</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_len</th>\n",
       "      <th>web_type_0</th>\n",
       "      <th>web_type_7</th>\n",
       "      <th>rating</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>daily_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284</td>\n",
       "      <td>7828</td>\n",
       "      <td>22556</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 16, 17, 18, 23]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982662</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.200713</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321</td>\n",
       "      <td>13936</td>\n",
       "      <td>33144</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[0, 6, 13, 21, 23]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.064702</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254</td>\n",
       "      <td>9486</td>\n",
       "      <td>22241</td>\n",
       "      <td>[37, 32, 12, 21, 35, 15, 10, 5, 13, 0, 0]</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>[0, 7, 12, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.298231</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72194</td>\n",
       "      <td>[7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[3, 8, 12, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.808294</td>\n",
       "      <td>0.191706</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.322244</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>810</td>\n",
       "      <td>29044</td>\n",
       "      <td>[35, 39, 38, 34, 26, 22, 25, 24, 10, 23, 32]</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926617</td>\n",
       "      <td>0.073383</td>\n",
       "      <td>0.013570</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hall_id_trans  ag_id_trans  user_id_trans  \\\n",
       "0            284         7828          22556   \n",
       "1            321        13936          33144   \n",
       "2            254         9486          22241   \n",
       "3              0            0          72194   \n",
       "4            122          810          29044   \n",
       "\n",
       "                                 query_game_ids  query_game_ids_len  \\\n",
       "0             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                   1   \n",
       "1             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                   1   \n",
       "2     [37, 32, 12, 21, 35, 15, 10, 5, 13, 0, 0]                  10   \n",
       "3             [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                   2   \n",
       "4  [35, 39, 38, 34, 26, 22, 25, 24, 10, 23, 32]                  11   \n",
       "\n",
       "   game_id_trans               genres  genres_len  web_type_0  web_type_7  \\\n",
       "0             31  [1, 16, 17, 18, 23]           5    0.982662    0.017338   \n",
       "1             32   [0, 6, 13, 21, 23]           5    0.999251    0.000749   \n",
       "2             14     [0, 7, 12, 0, 0]           3    0.883117    0.116883   \n",
       "3              8     [3, 8, 12, 0, 0]           3    0.808294    0.191706   \n",
       "4             40      [0, 0, 0, 0, 0]           1    0.926617    0.073383   \n",
       "\n",
       "     rating  avg_rating  daily_count  \n",
       "0  0.001162    0.200713       1440.0  \n",
       "1  0.017104    0.064702        630.0  \n",
       "2  0.013348    0.298231          1.0  \n",
       "3  0.020599    0.322244        120.0  \n",
       "4  0.013570    0.095295        179.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_multi(df, multi_cols):\n",
    "    \"\"\"對於multivalent的欄位, 需要增加一個column去描述該欄位的長度\"\"\"\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "    ret = OrderedDict()\n",
    "    for colname, col in df.iteritems():\n",
    "        if colname in multi_cols:\n",
    "            lens = col.map(len)\n",
    "            ret[colname] = list(pad(col, padding=\"post\", maxlen=lens.max()))\n",
    "            ret[colname + \"_len\"] = lens.values\n",
    "        else:\n",
    "            ret[colname] = col.values\n",
    "    return ret\n",
    "\n",
    "def dataFn(data, n_batch=128, shuffle=False):\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "    def fn():\n",
    "        dataInner = data.copy()\n",
    "        indices = utils.get_minibatches_idx(len(dataInner), n_batch, shuffle=shuffle)\n",
    "        for ind in indices:\n",
    "            yield do_multi(dataInner.iloc[ind], [\"query_game_ids\",\"genres\"])\n",
    "    return fn\n",
    "\n",
    "for i, e in enumerate(dataFn(trProcessed, n_batch=5, shuffle=True)(), 1):\n",
    "    # print(e)\n",
    "    break\n",
    "pd.DataFrame(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mysql/Chris/BBLotteryRecommenderSys/LotteryMFDNN.py:154: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "dim = 32\n",
    "n_batch = 128\n",
    "#modelDir = \"./model-3.5.0/model_mf_with_dnn\"\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "model = ModelMfDNN(\n",
    "            n_items=n_game,\n",
    "            n_genres=n_genres,\n",
    "            n_hall=hall_le.classes_.shape[0],\n",
    "            n_ag=ag_le.classes_.shape[0],\n",
    "            max_n_genres = max_n_genres,\n",
    "            dim=dim,\n",
    "            reg=0.1,\n",
    "            dt = date.run_date,\n",
    "            learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset model: clean model dir: ./python-lottery-mfdnn-model-20190312/model_mf_with_dnn ...\n",
      "Epoch\tTrain Error\tVal Error\tElapsed Time\n",
      "01\t0.193\t\t0.201\t\t23.946 secs, saving ...\n",
      "02\t0.178\t\t0.197\t\t21.779 secs, saving ...\n",
      "03\t0.177\t\t0.196\t\t23.945 secs, saving ...\n",
      "04\t0.177\t\t0.195\t\t22.842 secs, saving ...\n",
      "05\t0.177\t\t0.195\t\t23.372 secs, saving ...\n",
      "06\t0.176\t\t0.195\t\t22.308 secs, saving ...\n",
      "07\t0.176\t\t0.195\t\t23.183 secs, saving ...\n",
      "08\t0.176\t\t0.195\t\t22.045 secs, saving ...\n",
      "09\t0.176\t\t0.195\t\t22.763 secs9564)\n",
      "10\t0.176\t\t0.195\t\t22.256 secs, saving ...\n",
      "11\t0.176\t\t0.195\t\t23.463 secs9146)\n",
      "12\t0.176\t\t0.194\t\t22.726 secs, saving ...\n",
      "13\t0.176\t\t0.194\t\t22.768 secs, saving ...\n",
      "14\t0.176\t\t0.194\t\t22.430 secs, saving ...\n",
      "15\t0.176\t\t0.194\t\t23.136 secs8747)\n",
      "16\t0.176\t\t0.194\t\t22.026 secs, saving ...\n",
      "17\t0.176\t\t0.193\t\t22.945 secs, saving ...\n",
      "18\t0.175\t\t0.194\t\t23.270 secs8747)\n",
      "19\t0.175\t\t0.193\t\t23.166 secs, saving ...\n",
      "20\t0.175\t\t0.193\t\t21.907 secs8365)\n",
      "21\t0.175\t\t0.193\t\t22.855 secs, saving ...\n",
      "22\t0.175\t\t0.193\t\t22.391 secs, saving ...\n",
      "23\t0.175\t\t0.193\t\t22.548 secs8365)\n",
      "24\t0.175\t\t0.193\t\t23.690 secs, saving ...\n",
      "25\t0.175\t\t0.193\t\t22.250 secs, saving ...\n",
      "26\t0.175\t\t0.193\t\t23.562 secs8000)\n",
      "27\t0.174\t\t0.192\t\t22.771 secs, saving ...\n",
      "28\t0.174\t\t0.192\t\t23.585 secs, saving ...\n",
      "29\t0.174\t\t0.192\t\t22.869 secs, saving ...\n",
      "30\t0.174\t\t0.192\t\t23.413 secs, saving ...\n",
      "31\t0.174\t\t0.192\t\t22.700 secs, saving ...\n",
      "32\t0.174\t\t0.192\t\t23.167 secs, saving ...\n",
      "33\t0.174\t\t0.192\t\t23.701 secs, saving ...\n",
      "34\t0.174\t\t0.191\t\t22.661 secs, saving ...\n",
      "35\t0.174\t\t0.191\t\t24.367 secs, saving ...\n",
      "36\t0.174\t\t0.191\t\t22.844 secs7317)\n",
      "37\t0.173\t\t0.191\t\t23.721 secs, saving ...\n",
      "38\t0.173\t\t0.191\t\t22.045 secs, saving ...\n",
      "39\t0.173\t\t0.190\t\t23.228 secs, saving ...\n",
      "40\t0.173\t\t0.190\t\t22.770 secs, saving ...\n",
      "41\t0.173\t\t0.190\t\t23.253 secs, saving ...\n",
      "42\t0.173\t\t0.190\t\t23.460 secs6998)\n",
      "43\t0.173\t\t0.190\t\t22.497 secs, saving ...\n",
      "44\t0.172\t\t0.189\t\t23.861 secs, saving ...\n",
      "45\t0.172\t\t0.189\t\t22.452 secs, saving ...\n",
      "46\t0.172\t\t0.189\t\t22.930 secs, saving ...\n",
      "47\t0.172\t\t0.189\t\t23.740 secs6692)\n",
      "48\t0.172\t\t0.188\t\t23.721 secs, saving ...\n",
      "49\t0.172\t\t0.188\t\t23.203 secs6692)\n",
      "50\t0.172\t\t0.188\t\t22.397 secs, saving ...\n",
      "51\t0.172\t\t0.188\t\t23.499 secs6400)\n",
      "52\t0.171\t\t0.188\t\t22.064 secs, saving ...\n",
      "53\t0.171\t\t0.188\t\t22.826 secs, saving ...\n",
      "54\t0.171\t\t0.187\t\t21.889 secs, saving ...\n",
      "55\t0.171\t\t0.187\t\t23.425 secs, saving ...\n",
      "56\t0.171\t\t0.187\t\t22.051 secs6121)\n",
      "57\t0.171\t\t0.187\t\t23.324 secs, saving ...\n",
      "58\t0.171\t\t0.187\t\t22.749 secs6121)\n",
      "59\t0.171\t\t0.187\t\t24.039 secs, saving ...\n",
      "60\t0.171\t\t0.187\t\t23.041 secs, saving ...\n",
      "61\t0.171\t\t0.187\t\t22.342 secs, saving ...\n",
      "62\t0.171\t\t0.187\t\t23.621 secs5854)\n",
      "63\t0.171\t\t0.186\t\t23.085 secs, saving ...\n",
      "64\t0.170\t\t0.186\t\t22.856 secs5854)\n",
      "65\t0.170\t\t0.186\t\t22.618 secs5598)\n",
      "66\t0.170\t\t0.186\t\t23.085 secs5598)\n",
      "67\t0.170\t\t0.186\t\t22.640 secs5598)\n",
      "68\t0.170\t\t0.186\t\t22.762 secs5598)\n",
      "69\t0.170\t\t0.186\t\t23.130 secs, saving ...\n",
      "70\t0.170\t\t0.186\t\t23.975 secs, saving ...\n",
      "71\t0.170\t\t0.186\t\t22.494 secs, saving ...\n",
      "72\t0.170\t\t0.186\t\t23.633 secs, saving ...\n",
      "73\t0.170\t\t0.186\t\t23.228 secs5354)\n",
      "74\t0.170\t\t0.186\t\t23.632 secs, saving ...\n",
      "75\t0.170\t\t0.186\t\t22.351 secs5120)\n",
      "76\t0.170\t\t0.186\t\t24.040 secs, saving ...\n",
      "77\t0.170\t\t0.186\t\t22.279 secs, saving ...\n",
      "78\t0.170\t\t0.186\t\t23.452 secs5120)\n",
      "79\t0.170\t\t0.185\t\t23.139 secs, saving ...\n",
      "80\t0.170\t\t0.185\t\t22.536 secs, saving ...\n",
      "81\t0.170\t\t0.186\t\t22.598 secs4897)\n",
      "82\t0.169\t\t0.185\t\t23.704 secs, saving ...\n",
      "83\t0.169\t\t0.185\t\t23.107 secs, saving ...\n",
      "84\t0.169\t\t0.185\t\t22.097 secs4897)\n",
      "85\t0.169\t\t0.185\t\t22.543 secs4683)\n",
      "86\t0.169\t\t0.185\t\t21.540 secs4683)\n",
      "87\t0.169\t\t0.185\t\t22.968 secs, saving ...\n",
      "88\t0.169\t\t0.185\t\t21.902 secs4683)\n",
      "89\t0.169\t\t0.185\t\t22.949 secs4683)\n",
      "90\t0.169\t\t0.185\t\t21.825 secs, saving ...\n",
      "91\t0.169\t\t0.185\t\t23.038 secs, saving ...\n",
      "92\t0.169\t\t0.185\t\t22.818 secs4478)\n",
      "93\t0.169\t\t0.185\t\t22.553 secs, saving ...\n",
      "94\t0.169\t\t0.185\t\t24.184 secs4478)\n",
      "95\t0.169\t\t0.185\t\t22.324 secs4283)\n",
      "96\t0.169\t\t0.185\t\t23.460 secs4283)\n",
      "97\t0.169\t\t0.185\t\t22.314 secs4283)\n",
      "98\t0.169\t\t0.185\t\t22.446 secs4283)\n",
      "99\t0.169\t\t0.185\t\t23.088 secs4283)\n",
      "100\t0.168\t\t0.185\t\t23.814 secs, saving ...\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./java-lottery-mfdnn-model-20190312/saved_model.pb'\n",
      "training used time :  4353.838456207886 sec\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=model.graph) as sess:\n",
    "    model.fit(sess, dataFn(trProcessed, n_batch=n_batch, shuffle=True), dataFn(teProcessed, n_batch=n_batch), nEpoch=100, reset=True)\n",
    "    model.save_model(sess)\n",
    "print(\"training used time : \",time_delta.tick(timeit.default_timer()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(model.java_model_path,'model'))\n",
    "\n",
    "for f in os.listdir(model.java_model_path):\n",
    "    shutil.move(os.path.join(model.java_model_path,f), os.path.join(model.java_model_path,'model'))#'./java-lottery-mfdnn-model-20190123/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncToJson(item_class):\n",
    "    item_dict = {}\n",
    "    for i,c in enumerate(item_class):\n",
    "        try:\n",
    "            item_dict[int(c)] = int(i)\n",
    "        except:\n",
    "            item_dict[c] = int(i)\n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class genrateJson:\n",
    "    \n",
    "    def __init__(self,hall_le,ag_le,web_le):\n",
    "        global model\n",
    "        self.hall_le = hall_le\n",
    "        self.ag_le = ag_le\n",
    "        self.web_le = web_le\n",
    "        self.dir = \"java-lottery-mfdnn-model-\"+str(dateToNumeric(model.dt))#'json-'+str(dateToNumeric(model.dt))\n",
    "        #os.mkdir(self.dir)\n",
    "    def userLabel(self):\n",
    "        \n",
    "        label_dict = {}\n",
    "#label_dict['gameType'] = labelEncToJson(item_le.classes_)\n",
    "        label_dict['hallId'] = labelEncToJson(hall_le.classes_)\n",
    "        label_dict['agId'] = labelEncToJson(ag_le.classes_)\n",
    "        label_dict['webId'] = labelEncToJson(web_le.classes_)\n",
    "        \n",
    "        with open(os.path.join(self.dir,'userLabel.json'), 'w') as fp:\n",
    "            json.dump(label_dict,fp,indent=4,sort_keys=True)\n",
    "    \n",
    "    def game(self):\n",
    "        \n",
    "        itemDictToJson = {}\n",
    "        pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "        itemDictToJson[\"sequence\"] = [str(i) for i in tr_item_data.game_id_trans.tolist()]#tr_item_data.game_id_trans.tolist()\n",
    "        for _,i in tr_item_data.iterrows():\n",
    "            itemDictToJson[i.game_id_trans] = {}\n",
    "            itemDictToJson[i.game_id_trans][\"dailyCount\"] = i.daily_count\n",
    "            itemDictToJson[i.game_id_trans][\"gameType\"] = int(item_le.inverse_transform([i.game_id_trans])[0])\n",
    "            itemDictToJson[i.game_id_trans][\"genres\"] = pad([i.genres],padding=\"post\",maxlen=tr_item_data.genres.map(len).max()).tolist()[0]#i.genres\n",
    "            itemDictToJson[i.game_id_trans][\"genresLength\"] = len(i.genres)\n",
    "            itemDictToJson[i.game_id_trans][\"avgRating\"] = i.avg_rating\n",
    "            itemDictToJson[i.game_id_trans][\"candidateGameId\"] = i.game_id_trans\n",
    "            itemDictToJson[i.game_id_trans][\"webType0\"] = i.web_type_0\n",
    "            itemDictToJson[i.game_id_trans][\"webType7\"] = i.web_type_7\n",
    "            \n",
    "        with open(os.path.join(self.dir,'game.json'), 'w') as fp:\n",
    "            json.dump(itemDictToJson,fp,indent=4)\n",
    "    def delete(self):\n",
    "        shutil.rmtree(self.dir,ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/mysql/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "gJ = genrateJson(hall_le,ag_le,web_le)\n",
    "gJ.userLabel()\n",
    "gJ.game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mysql/Chris/BBLotteryRecommenderSys/python-lottery-mfdnn-model-20190312.zip'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive(model.java_model_path,'zip',model.java_model_path)\n",
    "shutil.make_archive(os.path.split(model.modelDir)[0],'zip',os.path.split(model.modelDir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./python_model/python-lottery-mfdnn-model-20190312.zip'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move(\"java-lottery-mfdnn-model-\"+str(dateToNumeric(model.dt))+\".zip\", \"./java_model\")\n",
    "shutil.move(\"python-lottery-mfdnn-model-\"+str(dateToNumeric(model.dt))+\".zip\", \"./python_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shutil.rmtree(\"java-lottery-mfdnn-model-\"+str(dateToNumeric(model.dt)),ignore_errors=True)\n",
    "shutil.rmtree(\"python-lottery-mfdnn-model-\"+str(dateToNumeric(model.dt)),ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shutil.make_archive(os.path.join('json_file',gJ.dir),'zip',gJ.dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gJ.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(model.modelDir.split(\"/\")[1],ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
