{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, json, time\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, itertools, shutil,pymysql\n",
    "import datetime\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "# 多核\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "#\n",
    "import tensorflow as tf\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict, Counter\n",
    "os = __import__('os')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()\n",
    "def dateToNumeric(date):\n",
    "    return date.year*10000+date.month*100+date.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMfDNN(object):\n",
    "    def __init__(self,\n",
    "                 n_items,\n",
    "                 n_genres,\n",
    "                 n_hall,\n",
    "                 n_ag,\n",
    "                 max_n_genres,\n",
    "                 dim=32,\n",
    "                 reg=0.05,\n",
    "                 learning_rate=0.01,\n",
    "                 dt = dt):\n",
    "        \"\"\"初始化 Tensorflow Graph\"\"\"\n",
    "        \n",
    "        self.dt = dt\n",
    "        modelDir=\"./python-lottery-mfdnn-model-\"+str(dateToNumeric(dt))+\"/model_mf_with_dnn\"\n",
    "        self.java_model_path = './java-lottery-mfdnn-model-'+str(dateToNumeric(dt))\n",
    "        self.max_n_genres = max_n_genres\n",
    "        self.n_items = n_items\n",
    "        self.n_genres = n_genres\n",
    "        self.n_hall = n_hall\n",
    "        self.n_ag = n_ag\n",
    "        self.ftr_cols = OrderedDict()\n",
    "        self.initial_learning_rate = learning_rate\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            with tf.variable_scope(\"decay_lr\"):\n",
    "                self.global_step = tf.Variable(0,trainable= False)\n",
    "                self.learning_rate = tf.train.exponential_decay(self.initial_learning_rate,\\\n",
    "                                           global_step=self.global_step,\\\n",
    "                                           decay_steps=5,decay_rate=0.8)\n",
    "                self.add_global = self.global_step.assign_add(1)\n",
    "            # inputs/id_user:0\n",
    "            with tf.variable_scope(\"inputs\"):\n",
    "                self.lr =tf.placeholder(tf.float32,None,name=\"lr\")\n",
    "                self.isTrain = tf.placeholder(tf.bool, None,name=\"isTrain\")\n",
    "                # user data\n",
    "                self.hall_id = tf.placeholder(tf.int32,[None],name=\"hall_id\")\n",
    "                self.ag_id = tf.placeholder(tf.int32,[None],name=\"ag_id\")\n",
    "                self.user_id = tf.placeholder(tf.int32, [None],name=\"user_id\")\n",
    "                self.query_game_ids = tf.placeholder(tf.int32, [None, None],name=\"query_game_ids\")\n",
    "                self.query_game_ids_len = tf.placeholder(tf.int32, [None],name=\"query_game_ids_len\")\n",
    "              #  self.web_like_type = tf.placeholder(tf.int32,[None],name=\"web_like_type\")\n",
    "                # item data\n",
    "                self.genres = tf.placeholder(tf.int32, [None, None],name=\"genres\")\n",
    "                self.genres_len = tf.placeholder(tf.int32, [None],name=\"genres_len\")\n",
    "                self.avg_rating = tf.placeholder(tf.float32, [None],name=\"avg_rating\")\n",
    "                \n",
    "                self.candidate_game_id = tf.placeholder(tf.int32, [None],name=\"candidate_game_id\")\n",
    "                self.web_type_0 = tf.placeholder(tf.float32,[None],name=\"web_type_0\")\n",
    "                self.web_type_7 = tf.placeholder(tf.float32,[None],name=\"web_type_7\")\n",
    "                self.rating = tf.placeholder(tf.float32, [None],name=\"rating\")\n",
    "\n",
    "            init_fn = tf.glorot_normal_initializer()\n",
    "            emb_init_fn = tf.glorot_uniform_initializer()\n",
    "            self.b_global = tf.Variable(emb_init_fn(shape=[]), name=\"b_global\")\n",
    "            with tf.variable_scope(\"embedding\"):\n",
    "                self.w_query_game_ids = tf.Variable(emb_init_fn(shape=[self.n_items, dim]), name=\"w_query_game_ids\")\n",
    "                self.b_query_game_ids = tf.Variable(emb_init_fn(shape=[dim]), name=\"b_query_game_ids\")\n",
    "                self.w_candidate_game_id = tf.Variable(init_fn(shape=[self.n_items, dim]), name=\"w_candidate_game_id\")\n",
    "                self.b_candidate_game_id = tf.Variable(init_fn(shape=[dim + self.max_n_genres + 3]), name=\"b_candidate_game_id\")\n",
    "                self.w_genres = tf.Variable(emb_init_fn(shape=[self.n_genres, self.max_n_genres]), name=\"w_genres\")\n",
    "                self.w_hall = tf.Variable(emb_init_fn(shape=[self.n_hall,dim]),name=\"w_hall\")\n",
    "                self.w_ag =tf.Variable(emb_init_fn(shape=[self.n_ag,dim]),name=\"w_ag\")\n",
    "               # self.w_web_like_type = tf.Variable(emb_init_fn(shape = [2,dim]),name= \"w_web_like_type\")\n",
    "                # query_game embedding\n",
    "                '''sqrtn aggregation(pooling), X: data, W: weight\n",
    "                       X_1*W_1 + X_2*W_2 + ... + X_n*W_n / sqrt(W_1**2 + W_2**2 + ... W_n**2)\n",
    "                     = weighted sum of X and normalized W\n",
    "                   here data = self.query_emb, weight = query_game_mask '''\n",
    "                self.query_emb = tf.nn.embedding_lookup(self.w_query_game_ids, self.query_game_ids)\n",
    "                query_game_mask = tf.expand_dims(tf.nn.l2_normalize(tf.to_float(tf.sequence_mask(self.query_game_ids_len)), 1), -1)\n",
    "                self.query_emb = tf.reduce_sum(self.query_emb * query_game_mask, 1)\n",
    "                self.query_bias = tf.matmul(self.query_emb, self.b_query_game_ids[:, tf.newaxis])\n",
    "                # hall,ag embedding\n",
    "                self.hall_emb = tf.nn.embedding_lookup(self.w_hall,self.hall_id) \n",
    "                self.ag_emb = tf.nn.embedding_lookup(self.w_ag,self.ag_id)\n",
    "                # web like type embedding\n",
    "               # self.web_like_emb = tf.nn.embedding_lookup(self.w_web_like_type,self.web_like_type) \n",
    "                # candidate_game embedding\n",
    "                self.candidate_emb = tf.nn.embedding_lookup(self.w_candidate_game_id, self.candidate_game_id)\n",
    "\n",
    "                # genres embedding\n",
    "                '''sqrtn aggregation(pooling), X: data, W: weight\n",
    "                       X_1*W_1 + X_2*W_2 + ... + X_n*W_n / sqrt(W_1**2 + W_2**2 + ... W_n**2)\n",
    "                     = weighted sum of X and normalized W\n",
    "                   here data = self.genres_emb, weight = genres_mask '''\n",
    "                self.genres_emb = tf.nn.embedding_lookup(self.w_genres, tf.to_int32(self.genres))\n",
    "                genres_mask = tf.expand_dims( tf.nn.l2_normalize(tf.to_float(tf.sequence_mask(self.genres_len)), 1), -1)\n",
    "                self.genres_emb = tf.reduce_sum(self.genres_emb * genres_mask, 1)\n",
    "            \n",
    "            with tf.variable_scope(\"dnn\"):\n",
    "                # encode [item embedding + item metadata]\n",
    "                self.item_repr = tf.concat([self.candidate_emb, self.genres_emb, self.avg_rating[:, tf.newaxis], \\\n",
    "                                           self.web_type_0[:,tf.newaxis],self.web_type_7[:,tf.newaxis]], 1)\n",
    "                \n",
    "                self.user_repr = tf.concat([self.query_emb,self.hall_emb,self.ag_emb],1)\n",
    "                self.candidate_bias = tf.matmul(self.item_repr, self.b_candidate_game_id[:, tf.newaxis])\n",
    "                \n",
    "                dp_scale = 0.5\n",
    "              #  regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "                self.item_repr = tf.layers.dense(self.item_repr, dim, kernel_initializer=init_fn, \\\n",
    "                                                 activation=tf.nn.relu)\n",
    "                self.item_repr = tf.layers.dense(self.item_repr, dim, kernel_initializer=init_fn, \\\n",
    "                                                 activation=tf.nn.relu)\n",
    "                self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)\n",
    "#                 self.item_repr = tf.layers.dense(self.item_repr, dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "#                 self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)\n",
    "                self.user_repr = tf.layers.dense(self.user_repr,dim,kernel_initializer=init_fn,activation=tf.nn.relu)\n",
    "                self.user_repr = tf.layers.dense(self.user_repr,dim,kernel_initializer=init_fn,activation=tf.nn.relu)\n",
    "                self.user_repr = tf.layers.dropout(self.user_repr, dp_scale, training=self.isTrain)\n",
    "#                 self.item_repr = tf.layers.dense(self.item_repr, dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "#                 self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)\n",
    "#                 self.item_repr = tf.layers.dense(self.item_repr, dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "#                 self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)\n",
    "                \n",
    "            with tf.variable_scope(\"computation\"):\n",
    "                infer = tf.reduce_sum(self.user_repr * self.item_repr, 1, keep_dims=True)\n",
    "                infer = tf.add(infer, self.b_global)\n",
    "                infer = tf.add(infer, self.query_bias)\n",
    "                self.infer = tf.add(infer, self.candidate_bias, name=\"infer\")\n",
    "\n",
    "                # one query for all items\n",
    "              #  self.pred = tf.matmul(self.user_repr, tf.transpose(self.item_repr)) + \\\n",
    "               #             tf.reshape(self.candidate_bias, (1, -1)) + self.query_bias + self.b_global\n",
    "                \n",
    "                self.pred = tf.add(tf.add(tf.add(tf.matmul(self.user_repr,tf.transpose(self.item_repr)), \n",
    "                                          tf.reshape(self.candidate_bias, (1, -1))),self.query_bias),self.b_global,name=\"pred\")\n",
    "                pass\n",
    "\n",
    "            with tf.variable_scope(\"loss\"):\n",
    "              #  self.regularizer = reg * tf.add(tf.nn.l2_loss(self.query_emb), tf.nn.l2_loss(self.candidate_emb))\n",
    "               # l2_layer_loss = tf.losses.get_regularization_loss()\n",
    "                self.loss = tf.losses.mean_squared_error(labels=self.rating[:, tf.newaxis], predictions=self.infer)# + \\\n",
    "                           # self.regularizer + l2_layer_loss\n",
    "             #   self.loss =tf.nn.softmax_cross_entropy_with_logits(labels=self.rating[:,tf.newaxis],logits=self.infer)\n",
    "                # for eval\n",
    "                self.rmse_loss = tf.sqrt(self.loss)\n",
    "                self.mae_loss = tf.reduce_mean(tf.abs(self.infer - self.rating[:, tf.newaxis]))\n",
    "                pass\n",
    "\n",
    "            with tf.variable_scope(\"train\"):\n",
    "                #self.train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "                self.train_op = tf.train.AdagradOptimizer(learning_rate).minimize(self.loss)\n",
    "                #self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "                #self.train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss)\n",
    "                #self.train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "                pass\n",
    "\n",
    "            self.saver = tf.train.Saver(tf.global_variables())\n",
    "            self.graph = graph\n",
    "            self.modelDir = modelDir\n",
    "            \n",
    "    def resetModel(self, modelDir):\n",
    "        \n",
    "        shutil.rmtree(path=modelDir, ignore_errors=True)\n",
    "        os.makedirs(modelDir)\n",
    "\n",
    "    def feed_dict(self, data,lr, mode=\"train\"):\n",
    "        ret = {\n",
    "            self.hall_id:data[\"hall_id_trans\"],\n",
    "            self.ag_id:data[\"ag_id_trans\"],\n",
    "            self.user_id: data[\"user_id_trans\"],\n",
    "            self.query_game_ids: data[\"query_game_ids\"],\n",
    "            self.query_game_ids_len: data[\"query_game_ids_len\"],\n",
    "            self.genres: data[\"genres\"],\n",
    "            self.genres_len: data[\"genres_len\"],\n",
    "            self.avg_rating: data[\"avg_rating\"],\n",
    "            #self.web_like_type: data[\"web_like_type\"],\n",
    "            self.web_type_0 : data[\"web_type_0\"],\n",
    "            self.web_type_7 : data[\"web_type_7\"],\n",
    "        #    self.year: data[\"year\"],\n",
    "            self.candidate_game_id: data[\"game_id_trans\"]\n",
    "        }\n",
    "        ret[self.lr] = lr\n",
    "        ret[self.isTrain] = False\n",
    "        if mode != \"infer\":\n",
    "            ret[self.rating] = data[\"rating\"]\n",
    "            \n",
    "            if mode == \"train\":\n",
    "                ret[self.isTrain] = True\n",
    "            elif mode == \"eval\":\n",
    "                pass\n",
    "        return ret\n",
    "\n",
    "    def fit(self, sess, trainGen, testGen, reset=False, nEpoch=50):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if reset:\n",
    "            print(\"reset model: clean model dir: {} ...\".format(self.modelDir))\n",
    "            self.resetModel(self.modelDir)\n",
    "        # try: 試著重上次儲存的model再次training\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "\n",
    "        start = time.time()\n",
    "        print(\"%s\\t%s\\t%s\\t%s\" % (\"Epoch\", \"Train Error\", \"Val Error\", \"Elapsed Time\"))\n",
    "        minLoss = 1e7\n",
    "        for ep in range(1, nEpoch + 1):\n",
    "            tr_loss, tr_total = 0, 0\n",
    "            if ep % 5 == 0:\n",
    "                _,lr = sess.run([self.add_global,self.learning_rate])\n",
    "            else :\n",
    "                lr = sess.run(self.learning_rate)\n",
    "            for i, data in enumerate(trainGen(), 1):\n",
    "                loss, _ = sess.run([self.rmse_loss, self.train_op], feed_dict=self.feed_dict(data,lr, mode=\"train\"))\n",
    "                tr_loss += loss ** 2 * len(data[\"query_game_ids\"])\n",
    "                tr_total += len(data[\"query_game_ids\"])\n",
    "               \n",
    "                print(\"\\rtrain loss: {:.3f} (lr : %.6f)\".format(loss)%lr, end=\"\")\n",
    "            if testGen is not None:\n",
    "                epochLoss = self.epochLoss(sess, testGen)\n",
    "\n",
    "            tpl = \"\\r%02d\\t%.3f\\t\\t%.3f\\t\\t%.3f secs\"\n",
    "            if minLoss > epochLoss:\n",
    "                tpl += \", saving ...\"\n",
    "                self.saver.save(sess, os.path.join(self.modelDir, 'model'), global_step=ep)\n",
    "                minLoss = epochLoss\n",
    "\n",
    "            end = time.time()\n",
    "            print(tpl % (ep, np.sqrt(tr_loss / tr_total), epochLoss, end - start))\n",
    "            start = end\n",
    "        return self\n",
    "\n",
    "    def ckpt(self, sess, modelDir):\n",
    "        \"\"\"load latest saved model\"\"\"\n",
    "        latestCkpt = tf.train.latest_checkpoint(modelDir)\n",
    "        if latestCkpt:\n",
    "            self.saver.restore(sess, latestCkpt)\n",
    "        return latestCkpt\n",
    "\n",
    "    def epochLoss(self, sess, dataGen, tpe=\"rmse\"):\n",
    "        totLoss, totCnt = 0, 0\n",
    "        for data in dataGen():\n",
    "            lossTensor = self.rmse_loss if tpe == \"rmse\" else self.mae_loss\n",
    "            \n",
    "            loss = sess.run(lossTensor, feed_dict=self.feed_dict(data,0, mode=\"eval\"))\n",
    "            #print(loss)\n",
    "            totLoss += (loss ** 2 if tpe == \"rmse\" else loss) * len(data[\"query_game_ids\"])\n",
    "            totCnt += len(data[\"query_game_ids\"])\n",
    "        return np.sqrt(totLoss / totCnt) if tpe == \"rmse\" else totLoss / totCnt\n",
    "\n",
    "    def predict(self, sess, user_queries, items):\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return sess.run(self.pred, feed_dict={\n",
    "            self.isTrain: False,\n",
    "            self.hall_id:user_queries[\"hall_id_trans\"],\n",
    "            self.ag_id:user_queries[\"ag_id_trans\"],\n",
    "            self.user_id: user_queries[\"user_id_trans\"],\n",
    "            self.query_game_ids: user_queries[\"query_game_ids\"],\n",
    "            self.query_game_ids_len: user_queries[\"query_game_ids_len\"],\n",
    "         #   self.web_like_type: user_queries[\"web_like_type\"],\n",
    "            ##################################\n",
    "            self.genres: items[\"genres\"],\n",
    "            self.genres_len: items[\"genres_len\"],\n",
    "            self.avg_rating: items[\"avg_rating\"],\n",
    "            self.web_type_0 : items[\"web_type_0\"],\n",
    "            self.web_type_7 : items[\"web_type_7\"],\n",
    "            #self.year: items[\"year\"],\n",
    "            self.candidate_game_id: items[\"candidate_game_id\"]\n",
    "        })\n",
    "\n",
    "    def evaluateRMSE(self, sess, dataGen):\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return self.epochLoss(sess, dataGen, tpe=\"rmse\")\n",
    "\n",
    "    def evaluateMAE(self, sess, dataGen):\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return self.epochLoss(sess, dataGen, tpe=\"mae\")\n",
    "    \n",
    "    def save_model(self,session):\n",
    "        shutil.rmtree(path=self.java_model_path, ignore_errors=True)\n",
    "        signature = tf.saved_model.signature_def_utils.build_signature_def( \n",
    "        inputs = { \n",
    "        # user data\n",
    "        'input_lr': tf.saved_model.utils.build_tensor_info(self.lr),\n",
    "        'input_isTrain': tf.saved_model.utils.build_tensor_info(self.isTrain),\n",
    "        'input_hall_id': tf.saved_model.utils.build_tensor_info(self.hall_id),\n",
    "        'input_ag_id': tf.saved_model.utils.build_tensor_info(self.ag_id),\n",
    "        'input_query_game_ids': tf.saved_model.utils.build_tensor_info(self.query_game_ids),\n",
    "        'input_query_game_ids_len': tf.saved_model.utils.build_tensor_info(self.query_game_ids_len),\n",
    "       # 'input_web_like_type': tf.saved_model.utils.build_tensor_info(self.web_like_type),\n",
    "        # item data\n",
    "        'input_genres': tf.saved_model.utils.build_tensor_info(self.genres),\n",
    "        'input_genres_len': tf.saved_model.utils.build_tensor_info(self.genres_len),\n",
    "        'input_avg_rating': tf.saved_model.utils.build_tensor_info(self.avg_rating),\n",
    "        'input_candidate_game_id': tf.saved_model.utils.build_tensor_info(self.candidate_game_id),\n",
    "        'input_web_type_0': tf.saved_model.utils.build_tensor_info(self.web_type_0),\n",
    "        'input_web_type_7': tf.saved_model.utils.build_tensor_info(self.web_type_7),\n",
    "        },\n",
    "        outputs = {'output': tf.saved_model.utils.build_tensor_info(self.infer)})\n",
    "        b = tf.saved_model.builder.SavedModelBuilder(self.java_model_path)\n",
    "        b.add_meta_graph_and_variables(session,[tf.saved_model.tag_constants.SERVING],signature_def_map={tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature})\n",
    "        b.save() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
